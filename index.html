<!DOCTYPE html>
<html>

<head>
	<meta name=viewport content="width=device-width, initial-scale=1">
	<meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">

	<title>Joris Guérin</title>

	<link rel="icon" type="image/jpg" href="images/icon.jpeg">
	<link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
	<link href="styles/style.css" rel="stylesheet">

	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
</head>

<body>
<table width="860" border="0" align="center" cellspacing="0" cellpadding="0">
<tr>
<td>
	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
		<tr>
			<td width="90%" valign="middle">
				<p align="center">
					<name>Joris Guérin</name>
				</p>
				<p align=center>
          <a href="mailto:jorisguerin<dot>research<at>gmail<dot>com">Email</a> &nbsp/&nbsp
					<a href="documents/CV_full.pdf">CV</a> &nbsp/&nbsp
          <a href="https://github.com/jorisguerin">Github</a> &nbsp/&nbsp
          <a href="https://scholar.google.fr/citations?user=gO-31VYAAAAJ&hl=fr&authuser=1&oi=sra">Scholar</a> &nbsp/&nbsp
          <a href="https://twitter.com/jorisguerin/">Twitter</a> &nbsp/&nbsp
					<a href="https://tel.archives-ouvertes.fr/tel-03096508/document">Dissertation</a>
        </p>
				<p align="center">
					<br>
					Post-doctoral researcher at <a href="https://www.laas.fr/">LAAS-CNRS</a> - <a href="https://aniti.univ-toulouse.fr/"> ANITI</a>.
				</p>
			</td>
			<td width="10%">
				<img src="images/joris.png" style="float:right;width:200px;height:200px">
			</td>
		</tr>
	</table>

	<p align="justify">
		The research activities that I carry out study various aspects of machine learning and computer vision, with a focus on how they can be integrated within real-world applications. In particular, I am interested in the design and integration of perception components based on machine learning for cyber-physical systems, and in particular robotic systems. Since the beginning of my PhD in 2015, I have been involved in many projects focusing on different parts of the perception-decision-action paradigm, which is essential for autonomous robotic systems. In particular, I am interested about
		<ol>
	  <li>how a robotic system can learn to achieve actions in the real-world (reinforcement learning), </li>
	  <li>how it can use previous knowledge to understand the real-world (transfer learning), </li>
	  <li>how it can act to improve its understanding of the real-world (active vision), </li>
		<li>how our knowledge of the physics of the system can be leveraged to improve trust in the model (predictions correction).</li>
		</ol>

	</p>
	<br/>
	<div class="page_selector">
	<table width="80%" align="center" border="0" cellspacing="0" cellpadding="20">
	<tr>
			<td id="home">Home</td>
			<td id="publications">Publications</td>
			<td id="talks">Talks</td>
			<td id="teaching">Teaching</td>
			<td id="demos">Demos</td>
			<td id="others">Others</td>
	</tr>
	</table>
  </div>

	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
	<tbody>
	<tr>
		<td width="100%" valign="middle">
			<div class="content">
			<h2>News</h2>
			<ul>
				<li>
				<b>January 2021</b>: I submitted my application for the CNRS 2021 CRCN competition! Thanks a lot to the members of the RAP (LAAS-CNRS),
				ICAR (LIRMM) and ComSee (Institut Pascal) teams for their support.
				</li>
				<li>
				<b>January 2021</b>: Our paper <i>Combining pretrained CNN feature extractors to enhance clustering of complex natural images</i>
				was published in Neurocomputing!
				</li>
				<li>
				<b>November 2020</b>: I am joining the Artificial and Natural Intelligence Toulouse Institute (ANITI), where I will work with
				<a href="http://homepages.laas.fr/guiochet/">Jérémie Guiochet</a> and <a href="https://www.onera.fr/en/staff/kevin-delmas">Kévin Delmas</a>,
				on problems related to runtime monitoring of learning-based systems. A huge thanks to <a href="https://www.dca.ufrn.br/~lmarcos/">Luiz Marcos Gonçalves</a>
				for the welcome I received in the NatalNet lab. Now looking forward to start this new exciting project.
				</li>
				<li>
				<b>September 2020</b>: Our paper <i>Robust Detection of Objects under Periodic Motion with Gaussian Process Filtering</i> was
				accepted for oral presentation at ICMLA 2020!
				</li>
				<li>
				<b>August 2020</b>: Our paper <i>Towards practical implementations of person re-identification from full video frames</i>
				was published in Pattern Recognition Letters!
				</li>
				<li>
				<b>July 2020</b>: Our paper <i>Forecasting Covid-19 Dynamics in Brazil: A Data Driven Approach</i>
				has been published in the International Journal of Environmental Research and Public Health. Check it out to understand how clustering of regions can constitute a valuable preprocessing to improve prediction results!
				</li>
			</ul>
			<br>
			<h2>Relevant publications</h2>

			<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
			<tr>
			<td width="25%" valign="top">
				<img src="images/neurocomp.png" alt="Very good image summarizing the paper" width="280"></td>
			<td width="75%" valign="top">
			<p align="justify">
			<b><papertitle>Combining pretrained CNN feature extractors to enhance clustering of complex natural images</papertitle></b>
			<br>
			Joris Guérin, Stéphane Thiery,
			Éric Nyiri,
			<a href="http://www.oliviergibaru.org/">Olivier Gibaru</a>,
			<a href="https://homes.cs.washington.edu/~bboots/">Byron Boots</a>
			<br>
			<em>Neurocomputing</em>, 2021
			<br>
			[<a href="./documents/neurocomputing_arxiv.pdf">PDF</a>]
			[<a href="./documents/neurocomputing_arxiv.pdf">arXiv</a>]
			[<a href="./bib/neurocomputing.txt">bibtex</a>]
			<br><br>
			Recently, a common starting point for solving complex unsupervised image classification tasks is to use generic features,
			extracted with deep Convolutional Neural Networks (CNN) pretrained on a large and versatile dataset (ImageNet). However,
			in most research, the CNN architecture for feature extraction is chosen arbitrarily, without justification. This paper aims
			at providing insight on the use of pretrained CNN features for image clustering (IC). First, extensive experiments are conducted
			and show that, for a given dataset, the choice of the CNN architecture for feature extraction has a huge impact on the final clustering.
			These experiments also demonstrate that proper extractor selection for a given IC task is difficult. To solve this issue,
			we propose to rephrase the IC problem as a multi-view clustering (MVC) problem that considers features extracted from different
			architectures as different “views” of the same data. This approach is based on the assumption that information contained in the
			different CNN may be complementary, even when pretrained on the same data. We then propose a multi-input neural network architecture
			that is trained end-to-end to solve the MVC problem effectively. This approach is tested on nine natural image datasets,
			and produces state-of-the-art results for IC.
			</p>
			</td></tr>
			</table>


			<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
			<tr>
			<td width="25%" valign="top">
				<img src="images/icmla20.png" alt="Very good image summarizing the paper" width="280"></td>
			<td width="75%" valign="top">
			<p align="justify">
			<b><papertitle>Robust Detection of Objects under Periodic Motion with Gaussian Process Filtering</papertitle></b>
			<br>
			Joris Guérin,
			<a href="https://sigaa.ufrn.br/sigaa/public/docente/portal.jsf?siape=1350250">Anne Magaly de Paula Canuto</a>,
			<a href="https://www.dca.ufrn.br/~lmarcos/">Luiz Marcos Garcia Gonçalves </a>
			<br>
			<em>International Conference on Machine Learning and Applications (ICMLA)</em>, 2020
			<br>
			[<a href="https://arxiv.org/pdf/2009.14178.pdf">PDF</a>]
			[<a href="https://arxiv.org/abs/2009.14178">arXiv</a>]
			[<a href="./bib/icmla20.txt">bibtex</a>]
			[<a href="https://www.youtube.com/watch?v=gPATyKlvNz4">video presentation</a>]
			<br><br>
			Object Detection (OD) is an important task in Computer Vision with many practical applications.
			For some use cases, OD must be done on videos, where the object of interest has a periodic motion.
			In this paper, we formalize the problem of periodic OD, which consists in improving the performance
			of an OD model in the specific case where the object of interest is repeating similar spatio-temporal
			trajectories with respect to the video frames. The proposed approach is based on training a
			Gaussian Process to model the periodic motion, and use it to filter out the erroneous predictions
			of the OD model. By simulating various OD models and periodic trajectories, we demonstrate that
			this filtering approach, which is entirely data-driven, improves the detection performance by a large margin.
			</p>
			</td></tr>
			</table>

			<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
			<tr>
			<td width="25%" valign="top">
				<img src="images/iros18.png" alt="Very good image summarizing the paper" width="280"></td>
			<td width="75%" valign="top">
			<p align="justify"><b><papertitle>Semantically Meaningful View Selection</papertitle></b>
			<br>
			Joris Guérin,
			<a href="http://www.oliviergibaru.org/">Olivier Gibaru</a>,
			Éric Nyiri,
			Stéphane Thiery,
			<a href="https://homes.cs.washington.edu/~bboots/">Byron Boots</a>
			<br>
			<em>International Conference on Intelligent Robots and Systems (IROS)</em>, 2018
			<br>
			[<a href="https://arxiv.org/pdf/1807.10303.pdf">PDF</a>]
			[<a href="https://arxiv.org/abs/1807.10303">arXiv</a>]
			[<a href="./bib/iros18.txt">bibtex</a>]
			[<a href="./presentations/pres_iros18.pdf">presentation</a>]
			[<a href="https://github.com/jorisguerin/SemanticViewSelection_dataset">data</a>]
			<br><br>
			An understanding of the nature of objects could help robots to solve both
			high-level abstract tasks and improve performance at lower-level concrete tasks.
			Although deep learning has facilitated progress in image understanding, a robot's
			performance in problems like object recognition often depends on the angle
			from which the object is observed. Traditionally, robot sorting tasks rely on
			fixed top-down views of the objects. By changing its viewing angle, a robot
			can select a more semantically informative view leading to better performance
			for object recognition. In this paper, we introduce the problem of semantic
			view selection, which consists in finding good camera poses to gain semantic
			knowledge about observed objects. We propose a conceptual generic formulation
			of the problem, together with a relaxation based on clustering, to make it
			solvable. We then present a new image dataset consisting of around 10k images
			representing various views of 144 objects under different poses. Finally we use
			this dataset to propose a first solution to the problem by training a neural
			network to predict a "semantic score" from a top view image and camera pose.
			The views predicted to have higher scores are then showed to provide better
			clustering results than fixed top-down views.
			</p>
			</td></tr>
			</table>

			<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
			<tr>
			<td width="25%" valign="top">
				<img src="images/iecon16.png" alt="Very good image summarizing the paper" width="280"></td>
			<td width="75%" valign="top">
			<p align="justify"><b><papertitle>Learning local trajectories for high precision robotic tasks :
				application to KUKA LBR iiwa Cartesian positioning</papertitle></b>
			<br>
			Joris Guérin,
			<a href="http://www.oliviergibaru.org/">Olivier Gibaru</a>,
			Éric Nyiri,
			Stéphane Thiery
			<br>
			<em>IECON</em> 2016
			<br>
			[<a href="https://arxiv.org/pdf/1701.01497.pdf">PDF</a>]
			[<a href="https://arxiv.org/abs/1701.01497">arXiv</a>]
			[<a href="./bib/iecon16.txt">bibtex</a>]
			[<a href="./presentations/pres_iecon16.pdf">presentation</a>]
			[<a href="https://www.youtube.com/watch?v=Ekda9q3vv6Y">video</a>]
			<br><br>
			To ease the development of robot learning in industry, two conditions need
			to be fulfilled. Manipulators must be able to learn high accuracy and precision
			tasks while being safe for workers in the factory. In this paper, we extend
			our <a href="https://iopscience.iop.org/article/10.1088/1742-6596/783/1/012036/pdf">previous paper</a>,
			which consist in rapid learning of local high accuracy behaviors. By exploration and regression,
			linear and quadratic models are learnt for respectively the dynamics and cost function.
			Iterative Linear Quadratic Gaussian Regulator combined with cost quadratic regression
			can converge rapidly in the final stages towards high accuracy behavior as the cost
			function is modelled quite precisely. In this paper, both a different cost function
			and a second order improvement method are implemented within this framework. We also
			propose an analysis of the algorithm parameters through simulation for a positioning task.
			Finally, an experimental validation on a KUKA LBR iiwa robot is carried out. This collaborative
			robot manipulator can be easily programmed into safety mode, which makes it qualified for the
			second industry constraint stated above.
			</p>
			</td></tr>
			</table>

			<h2>Thesis</h2>

			<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
			<tr>
			<td width="25%" valign="top">
				<img src="images/thesis.png" alt="Very good image summarizing the paper" width="280"></td>
			<td width="75%" valign="top">
			<p align="justify">
			<b><papertitle>Machine learning improvements for robotic applications in industrial context:
						Case study of autonomous sorting</papertitle></b>
			<br>
			Joris Guérin
			<br>
			<em>Ph.D. dissertation</em> (2018)
			<br>
			[<a href="https://tel.archives-ouvertes.fr/tel-03096508/document">PDF</a>]
			[<a href="./bib/thesis.txt">bibtex</a>]
			[<a href="./presentations/pres_defense.pdf">presentation</a>]
			<br><br>
			Thanks to their flexible mechanical design, modern industrial robots can be programmed
			for different tasks without physical modification. In addition, they are highly
			instrumented and should be able to be responsive to their environment. However,
			the use of robots in industry is still restricted to repeatable tasks with low level
			of adaptability. In an industrial context, it is essential to program robots that can
			autonomously adapt to different applications and are robust to changes in working
			conditions. The machine learning framework for robot programming is well suited to
			design such kinds of adaptive and robust applications. Hence, in this thesis, several
			machine learning contributions are presented, aiming at designing smarter robotic
			applications, with a broader operational range. The methods developed are centered on
			autonomous sorting, but may be useful to address problems in many other subfields
			of robotics. Throughout this thesis, we propose new approaches to image clustering,
			optimal view selection, trajectory learning and stereo localization, with the objective
			of designing more universal robotic sorting applications.
			</p>
			</td></tr>
			</table>

			</div>
		</td>
	</tr>
	</tbody>
	</table>



	<!--Thanks-->
	<br>
  <p align="right">
    <font size="2">
      <a href="https://jonbarron.info">Awesome webpage...</a>
    </font>
  </p>
</td>
</tr>
</table>

<script src="scripts/publications.js"></script>
<script src="scripts/teaching.js"></script>
<script src="scripts/demos.js"></script>
<script src="scripts/others.js"></script>
<script src="scripts/home.js"></script>
<script src="scripts/talks.js"></script>

</body>
</html>
